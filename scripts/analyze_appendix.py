#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
é™„å½•è¡¨æ ¼åˆ†æå·¥å…·

ç”¨äºæŸ¥çœ‹æ•°å­¦å»ºæ¨¡é¢˜ç›®ä¸­"é™„å½•"æ–‡ä»¶å¤¹å†…çš„è¡¨æ ¼æ–‡ä»¶çš„å®Œæ•´å†…å®¹ã€‚
æ”¯æŒ .xlsx, .xls, .csv æ ¼å¼æ–‡ä»¶ã€‚

ä½¿ç”¨æ–¹æ³•ï¼š
    python analyze_appendix.py                    # åˆ†æå½“å‰ç›®å½•ä¸‹çš„ é™„å½•/ æ–‡ä»¶å¤¹
    python analyze_appendix.py --path ./data      # åˆ†ææŒ‡å®šè·¯å¾„
    python analyze_appendix.py --file é™„å½•1.xlsx  # åˆ†æå•ä¸ªæ–‡ä»¶

ä½œè€…ï¼šæ•°å­¦å»ºæ¨¡ Skill
ç‰ˆæœ¬ï¼š1.0.0
"""

import os
import sys
import argparse
from pathlib import Path
from typing import List, Dict, Any

try:
    import pandas as pd
except ImportError:
    print("âŒ é”™è¯¯ï¼šæœªå®‰è£… pandas åº“")
    print("è¯·è¿è¡Œï¼špip install pandas openpyxl xlrd")
    sys.exit(1)


def find_appendix_files(base_path: str = None) -> List[str]:
    """
    æŸ¥æ‰¾é™„å½•æ–‡ä»¶å¤¹ä¸­çš„æ‰€æœ‰è¡¨æ ¼æ–‡ä»¶

    å‚æ•°ï¼š
        base_path: åŸºç¡€è·¯å¾„ï¼Œé»˜è®¤ä¸ºå½“å‰å·¥ä½œç›®å½•

    è¿”å›ï¼š
        æ–‡ä»¶è·¯å¾„åˆ—è¡¨
    """
    if base_path is None:
        base_path = os.getcwd()

    # å°è¯•å¸¸è§çš„é™„å½•æ–‡ä»¶å¤¹åç§°
    appendix_names = ['é™„å½•', 'appendix', 'Appendix', 'é™„ä»¶', 'data', 'Data']
    found_files = []

    for appendix_name in appendix_names:
        appendix_path = os.path.join(base_path, appendix_name)

        if os.path.exists(appendix_path) and os.path.isdir(appendix_path):
            print(f"âœ… æ‰¾åˆ°é™„å½•æ–‡ä»¶å¤¹: {appendix_path}\n")

            # æŸ¥æ‰¾æ‰€æœ‰è¡¨æ ¼æ–‡ä»¶
            for filename in sorted(os.listdir(appendix_path)):
                if filename.endswith(('.xlsx', '.xls', '.csv')):
                    found_files.append(os.path.join(appendix_path, filename))

            if found_files:
                return found_files

    # å¦‚æœæ²¡æ‰¾åˆ°ï¼Œç›´æ¥åœ¨å½“å‰ç›®å½•æŸ¥æ‰¾
    print("âš ï¸  æœªæ‰¾åˆ°'é™„å½•'æ–‡ä»¶å¤¹ï¼Œåœ¨å½“å‰ç›®å½•æŸ¥æ‰¾è¡¨æ ¼æ–‡ä»¶...\n")
    for filename in sorted(os.listdir(base_path)):
        if filename.endswith(('.xlsx', '.xls', '.csv')):
            found_files.append(os.path.join(base_path, filename))

    return found_files


def print_dataframe(df: pd.DataFrame, max_cols: int = None):
    """
    å®Œæ•´æ‰“å° DataFrame çš„æ‰€æœ‰å†…å®¹

    å‚æ•°ï¼š
        df: pandas DataFrame
        max_cols: æœ€å¤§åˆ—æ•°æ˜¾ç¤ºé™åˆ¶ï¼ˆNoneè¡¨ç¤ºæ˜¾ç¤ºæ‰€æœ‰åˆ—ï¼‰
    """
    # è®¾ç½® pandas æ˜¾ç¤ºé€‰é¡¹ï¼Œæ˜¾ç¤ºæ‰€æœ‰è¡Œå’Œåˆ—
    pd.set_option('display.max_rows', None)
    pd.set_option('display.max_columns', None)
    pd.set_option('display.width', None)
    pd.set_option('display.max_colwidth', None)

    # æ‰“å°å®Œæ•´è¡¨æ ¼
    print(df.to_string())


def analyze_excel_file(filepath: str) -> Dict[str, Any]:
    """
    åˆ†æå¹¶å®Œæ•´è¾“å‡º Excel æ–‡ä»¶å†…å®¹

    å‚æ•°ï¼š
        filepath: Excel æ–‡ä»¶è·¯å¾„

    è¿”å›ï¼š
        åˆ†æç»“æœå­—å…¸
    """
    result = {
        'filename': os.path.basename(filepath),
        'type': 'Excel',
        'sheets': {}
    }

    try:
        # è¯»å–æ‰€æœ‰ sheet
        excel_file = pd.ExcelFile(filepath)
        sheet_names = excel_file.sheet_names

        for sheet_name in sheet_names:
            df = pd.read_excel(excel_file, sheet_name=sheet_name)

            result['sheets'][sheet_name] = {
                'rows': len(df),
                'columns': len(df.columns),
                'column_names': list(df.columns),
                'data': df
            }

    except Exception as e:
        result['error'] = str(e)

    return result


def analyze_csv_file(filepath: str) -> Dict[str, Any]:
    """
    åˆ†æå¹¶å®Œæ•´è¾“å‡º CSV æ–‡ä»¶å†…å®¹

    å‚æ•°ï¼š
        filepath: CSV æ–‡ä»¶è·¯å¾„

    è¿”å›ï¼š
        åˆ†æç»“æœå­—å…¸
    """
    result = {
        'filename': os.path.basename(filepath),
        'type': 'CSV',
    }

    try:
        # å°è¯•ä¸åŒçš„ç¼–ç 
        encodings = ['utf-8', 'utf-8-sig', 'gbk', 'gb2312', 'gb18030']
        df = None

        for encoding in encodings:
            try:
                df = pd.read_csv(filepath, encoding=encoding)
                result['encoding'] = encoding
                break
            except UnicodeDecodeError:
                continue

        if df is None:
            raise Exception("æ— æ³•è¯†åˆ«æ–‡ä»¶ç¼–ç ")

        result['sheets'] = {'Sheet1': {
            'rows': len(df),
            'columns': len(df.columns),
            'column_names': list(df.columns),
            'data': df
        }}

    except Exception as e:
        result['error'] = str(e)

    return result


def display_full_content(result: Dict[str, Any]):
    """
    å®Œæ•´æ˜¾ç¤ºè¡¨æ ¼å†…å®¹

    å‚æ•°ï¼š
        result: åˆ†æç»“æœå­—å…¸
    """
    print("=" * 120)
    print(f"ğŸ“„ æ–‡ä»¶å: {result['filename']}")
    print(f"ğŸ“‹ ç±»å‹: {result['type']}")

    if 'error' in result:
        print(f"âŒ é”™è¯¯: {result['error']}")
        print("=" * 120)
        return

    if 'encoding' in result:
        print(f"ğŸ”¤ ç¼–ç : {result['encoding']}")

    print("")

    for sheet_name, sheet_data in result['sheets'].items():
        print("-" * 120)
        print(f"ğŸ“Š å·¥ä½œè¡¨: {sheet_name}")
        print(f"ğŸ“ ç»´åº¦: {sheet_data['rows']} è¡Œ Ã— {sheet_data['columns']} åˆ—")
        print("")

        # åˆ—åä¿¡æ¯
        print("ğŸ“Œ åˆ—å:")
        for i, col in enumerate(sheet_data['column_names'], 1):
            print(f"   {i:2d}. {col}")

        print("")
        print("ğŸ“‹ å®Œæ•´æ•°æ®å†…å®¹:")
        print("=" * 120)

        # å®Œæ•´è¾“å‡ºæ•°æ®
        print_dataframe(sheet_data['data'])

        print("")
        print("=" * 120)
        print("")


def save_full_content(results: List[Dict[str, Any]], output_path: str):
    """
    ä¿å­˜å®Œæ•´å†…å®¹åˆ°æ–‡ä»¶

    å‚æ•°ï¼š
        results: åˆ†æç»“æœåˆ—è¡¨
        output_path: è¾“å‡ºæ–‡ä»¶è·¯å¾„
    """
    with open(output_path, 'w', encoding='utf-8') as f:
        for result in results:
            f.write("=" * 120 + "\n")
            f.write(f"ğŸ“„ æ–‡ä»¶å: {result['filename']}\n")
            f.write(f"ğŸ“‹ ç±»å‹: {result['type']}\n")

            if 'error' in result:
                f.write(f"âŒ é”™è¯¯: {result['error']}\n")
                f.write("=" * 120 + "\n\n")
                continue

            if 'encoding' in result:
                f.write(f"ğŸ”¤ ç¼–ç : {result['encoding']}\n")

            f.write("\n")

            for sheet_name, sheet_data in result['sheets'].items():
                f.write("-" * 120 + "\n")
                f.write(f"ğŸ“Š å·¥ä½œè¡¨: {sheet_name}\n")
                f.write(f"ğŸ“ ç»´åº¦: {sheet_data['rows']} è¡Œ Ã— {sheet_data['columns']} åˆ—\n")
                f.write("\n")

                # åˆ—åä¿¡æ¯
                f.write("ğŸ“Œ åˆ—å:\n")
                for i, col in enumerate(sheet_data['column_names'], 1):
                    f.write(f"   {i:2d}. {col}\n")

                f.write("\n")
                f.write("ğŸ“‹ å®Œæ•´æ•°æ®å†…å®¹:\n")
                f.write("=" * 120 + "\n")

                # å®Œæ•´è¾“å‡ºæ•°æ®
                f.write(sheet_data['data'].to_string())

                f.write("\n")
                f.write("=" * 120 + "\n\n")

    print(f"âœ… å®Œæ•´å†…å®¹å·²ä¿å­˜è‡³: {output_path}")


def main():
    parser = argparse.ArgumentParser(
        description='å®Œæ•´è¾“å‡ºé™„å½•è¡¨æ ¼æ–‡ä»¶çš„æ‰€æœ‰å†…å®¹',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ç¤ºä¾‹ï¼š
  python analyze_appendix.py
  python analyze_appendix.py --path ./data
  python analyze_appendix.py --file é™„å½•1.xlsx
  python analyze_appendix.py --save full_content.txt
        """
    )

    parser.add_argument(
        '--path', '-p',
        type=str,
        default=None,
        help='æŒ‡å®šè¦åˆ†æçš„è·¯å¾„ï¼ˆé»˜è®¤ä¸ºå½“å‰ç›®å½•ï¼‰'
    )

    parser.add_argument(
        '--file', '-f',
        type=str,
        default=None,
        help='åˆ†æå•ä¸ªæ–‡ä»¶'
    )

    parser.add_argument(
        '--save', '-s',
        type=str,
        default=None,
        help='ä¿å­˜å®Œæ•´å†…å®¹åˆ°æ–‡ä»¶'
    )

    args = parser.parse_args()

    # åˆ†æå•ä¸ªæ–‡ä»¶
    if args.file:
        if not os.path.exists(args.file):
            print(f"âŒ é”™è¯¯ï¼šæ–‡ä»¶ä¸å­˜åœ¨ - {args.file}")
            sys.exit(1)

        print(f"\nğŸ” åˆ†ææ–‡ä»¶: {args.file}\n")

        if args.file.endswith(('.xlsx', '.xls')):
            result = analyze_excel_file(args.file)
        elif args.file.endswith('.csv'):
            result = analyze_csv_file(args.file)
        else:
            print(f"âŒ é”™è¯¯ï¼šä¸æ”¯æŒçš„æ–‡ä»¶æ ¼å¼ - {args.file}")
            sys.exit(1)

        display_full_content(result)

        if args.save:
            save_full_content([result], args.save)

        sys.exit(0)

    # æŸ¥æ‰¾å¹¶åˆ†ææ‰€æœ‰æ–‡ä»¶
    base_path = args.path if args.path else os.getcwd()

    if not os.path.exists(base_path):
        print(f"âŒ é”™è¯¯ï¼šè·¯å¾„ä¸å­˜åœ¨ - {base_path}")
        sys.exit(1)

    print(f"\nğŸ” åœ¨è·¯å¾„ä¸­æŸ¥æ‰¾é™„å½•æ–‡ä»¶: {base_path}\n")

    files = find_appendix_files(base_path)

    if not files:
        print("âŒ æœªæ‰¾åˆ°ä»»ä½•è¡¨æ ¼æ–‡ä»¶ï¼ˆ.xlsx, .xls, .csvï¼‰")
        sys.exit(1)

    print(f"âœ… æ‰¾åˆ° {len(files)} ä¸ªæ–‡ä»¶\n")

    # åˆ†ææ‰€æœ‰æ–‡ä»¶
    results = []
    for filepath in files:
        print(f"ğŸ” æ­£åœ¨åˆ†æ: {os.path.basename(filepath)}")

        if filepath.endswith(('.xlsx', '.xls')):
            result = analyze_excel_file(filepath)
        elif filepath.endswith('.csv'):
            result = analyze_csv_file(filepath)
        else:
            continue

        results.append(result)

    # è¾“å‡ºç»“æœ
    print("\n" + "=" * 120)
    print("ğŸ“Š å®Œæ•´å†…å®¹è¾“å‡º")
    print("=" * 120 + "\n")

    for result in results:
        display_full_content(result)

    # ä¿å­˜æŠ¥å‘Š
    if args.save:
        save_full_content(results, args.save)

    print("âœ… åˆ†æå®Œæˆï¼")


if __name__ == '__main__':
    main()