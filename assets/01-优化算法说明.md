# 优化算法说明文档

## 概述

优化算法是数学建模中最常用的算法类型之一，用于求解在约束条件下使目标函数达到最优（最大或最小）的决策变量值。优化问题广泛存在于生产调度、资源分配、路径规划、参数优化等领域。

---

## 1. 线性规划 (Linear Programming, LP)

### 算法介绍

线性规划是一种数学方法，用于在满足线性约束条件下，求取线性目标函数的最大值或最小值。其标准形式为：

**目标函数**：
$$
\min Z = c_1x_1 + c_2x_2 + \cdots + c_nx_n
$$

**约束条件**：
$$
\begin{cases}
a_{11}x_1 + a_{12}x_2 + \cdots + a_{1n}x_n \leq b_1 \\
a_{21}x_1 + a_{22}x_2 + \cdots + a_{2n}x_n \leq b_2 \\
\vdots \\
a_{m1}x_1 + a_{m2}x_2 + \cdots + a_{mn}x_n \leq b_m \\
x_i \geq 0, \quad i=1,2,\ldots,n
\end{cases}
$$

**求解方法**：单纯形法、内点法

### 适用范围

| 题型类型 | 典型问题 | 特征 |
|---------|---------|------|
| 资源分配 | 生产计划、物资调配 | 线性目标函数 + 线性约束 |
| 运输问题 | 物资运输、最小费用流 | 供需平衡约束 |
| 指派问题 | 任务分配、人员安排 | 0-1变量约束 |
| 配料问题 | 饲料配方、化学混合 | 比例约束 |

### 可视化图表类型

- **可行域图**：二维问题的约束区域可视化
- **等值线图**：目标函数等值线与可行域关系
- **灵敏度分析图**：参数变化对最优解的影响
- **单纯形表**：单纯形法迭代过程表格

### 关键文献

| 论文名称 | 作者 | 年份 | 来源 |
|---------|------|------|------|
| Linear Programming and Extensions | George Dantzig | 1963 | Princeton University Press |
| Interior-point polynomial algorithms in convex programming | Nesterov & Nemirovski | 1994 | SIAM |

### 代码实现要点

```python
# 常用库：scipy.optimize.linprog, pulp, cvxpy
from scipy.optimize import linprog

# 标准形式：min c^T x subject to A_ub x <= b_ub
c = [-1, -2]  # 目标函数系数（求最小值）
A_ub = [[2, 1], [1, 3]]  # 不等式约束系数矩阵
b_ub = [10, 15]  # 不等式约束右侧值

result = linprog(c, A_ub=A_ub, b_ub=b_ub, bounds=[(0, None), (0, None)])
```

---

## 2. 整数规划 (Integer Programming, IP)

### 算法介绍

整数规划是线性规划的扩展，要求部分或全部决策变量取整数值。根据变量取值特点分为：

- **纯整数规划**：所有变量均为整数
- **混合整数规划**：部分变量为整数，部分为连续
- **0-1规划**：变量只能取0或1

**求解方法**：分支定界法、割平面法、分支定价法

### 适用范围

| 题型类型 | 典型问题 | 特征 |
|---------|---------|------|
| 设备选址 | 工厂选址、仓库布局 | 0-1选址变量 |
| 车辆路径 | 配送路线规划 | 逻辑约束 |
| 调度问题 | 作业调度、排班 | 时间离散化 |
| 背包问题 | 资源选择、投资组合 | 0-1选择变量 |

### 可视化图表类型

- **分支树图**：分支定界法搜索过程
- **甘特图**：调度问题的时间安排
- **网络图**：路径问题的可视化
- **解空间图**：整数解与连续解对比

### 关键文献

| 论文名称 | 作者 | 年份 | 来源 |
|---------|------|------|------|
| Integer Programming | Laurence Wolsey | 1998 | Wiley |
| Branch and bound: A survey | Lawler & Wood | 1966 | Operations Research |

### 代码实现要点

```python
# 常用库：pulp, ortools, gurobi, cplex
import pulp

# 创建整数规划问题
prob = pulp.LpProblem("整数规划示例", pulp.LpMaximize)

# 添加整数变量
x1 = pulp.LpVariable('x1', lowBound=0, cat='Integer')
x2 = pulp.LpVariable('x2', lowBound=0, cat='Binary')  # 0-1变量

# 添加目标函数和约束
prob += x1 + 2*x2
prob += x1 + x2 <= 10
```

---

## 3. 动态规划 (Dynamic Programming, DP)

### 算法介绍

动态规划是求解多阶段决策过程最优化的数学方法。其核心思想是将复杂问题分解为重叠子问题，通过保存子问题的解避免重复计算。

**基本要素**：
- **最优子结构**：问题的最优解包含子问题的最优解
- **重叠子问题**：子问题被重复计算
- **边界条件**：问题的初始状态

**状态转移方程**：
$$
dp[i] = \max_{j \in \text{choices}} \{dp[j] + cost(j, i)\}
$$

### 适用范围

| 题型类型 | 典型问题 | 特征 |
|---------|---------|------|
| 最短路径 | 多阶段路径规划 | 无后效性 |
| 资源分配 | 多阶段投资决策 | 阶段性决策 |
| 背包问题 | 物品装载组合 | 最优子结构 |
| 生产计划 | 多阶段生产调度 | 状态可转移 |
| 设备更新 | 最优更换策略 | 时间阶段划分 |

### 可视化图表类型

- **状态转移图**：各阶段状态之间的关系
- **决策树图**：不同决策路径的可视化
- **阶段图**：多阶段决策的时间轴
- **填表过程图**：DP表填充过程

### 关键文献

| 论文名称 | 作者 | 年份 | 来源 |
|---------|------|------|------|
| Dynamic Programming | Richard Bellman | 1957 | Princeton University Press |
| Optimal Capital Allocation | Merton | 1971 | Journal of Financial Economics |

### 代码实现要点

```python
# 背包问题示例
def knapsack(weights, values, capacity):
    n = len(weights)
    dp = [[0] * (capacity + 1) for _ in range(n + 1)]

    for i in range(1, n + 1):
        for w in range(capacity + 1):
            if weights[i-1] <= w:
                dp[i][w] = max(dp[i-1][w],
                              dp[i-1][w-weights[i-1]] + values[i-1])
            else:
                dp[i][w] = dp[i-1][w]
    return dp[n][capacity]
```

---

## 4. 遗传算法 (Genetic Algorithm, GA)

### 算法介绍

遗传算法是一种模拟自然进化过程的全局优化算法。通过选择、交叉、变异等操作，在解空间中搜索最优解。

**基本步骤**：
1. **初始化**：生成初始种群
2. **适应度评估**：计算每个个体的适应度值
3. **选择**：根据适应度选择父代个体
4. **交叉**：父代个体交叉产生子代
5. **变异**：子代个体发生随机变异
6. **终止判断**：满足终止条件则输出结果

**参数设置**：
- 种群大小：50-200
- 交叉概率：0.6-0.9
- 变异概率：0.001-0.1

### 适用范围

| 题型类型 | 典型问题 | 特征 |
|---------|---------|------|
| 复杂优化 | 多峰函数优化 | 非凸、非线性 |
| 调度问题 | 车间调度、课程表 | 组合优化 |
| 路径规划 | 旅行商问题 | NP-hard |
| 参数优化 | 神经网络参数 | 高维搜索空间 |

### 可视化图表类型

- **收敛曲线**：适应度随代数变化
- **种群分布图**：种群在解空间的分布
- **家族树图**：个体遗传关系
- **参数敏感性图**：参数对性能的影响

### 关键文献

| 论文名称 | 作者 | 年份 | 来源 |
|---------|------|------|------|
| Adaptation in Natural and Artificial Systems | John Holland | 1975 | University of Michigan Press |
| Genetic Algorithms in Search, Optimization | Goldberg | 1989 | Addison-Wesley |

### 代码实现要点

```python
# 常用库：DEAP, pyGA, sklearn.utils
import numpy as np
from deap import base, creator, tools, algorithms

# 定义问题类型
creator.create("FitnessMin", base.Fitness, weights=(-1.0,))
creator.create("Individual", list, fitness=creator.FitnessMin)

# 注册遗传算子
toolbox = base.Toolbox()
toolbox.register("mate", tools.cxTwoPoint)
toolbox.register("mutate", tools.mutGaussian, mu=0, sigma=1, indpb=0.1)
toolbox.register("select", tools.selTournament, tournsize=3)
```

---

## 5. 粒子群优化算法 (Particle Swarm Optimization, PSO)

### 算法介绍

粒子群优化算法模拟鸟群觅食行为，通过个体之间的信息共享来搜索最优解。每个粒子根据自身历史最优位置和群体全局最优位置更新速度和位置。

**速度更新公式**：
$$
v_{id}^{t+1} = w \cdot v_{id}^t + c_1 \cdot r_1 \cdot (pbest_{id} - x_{id}^t) + c_2 \cdot r_2 \cdot (gbest_d - x_{id}^t)
$$

**位置更新公式**：
$$
x_{id}^{t+1} = x_{id}^t + v_{id}^{t+1}
$$

**参数**：
- $w$：惯性权重（0.4-0.9）
- $c_1, c_2$：学习因子（通常取2.0）
- $r_1, r_2$：随机数（0-1之间）

### 适用范围

| 题型类型 | 典型问题 | 特征 |
|---------|---------|------|
| 连续优化 | 函数极值求解 | 连续变量 |
| 神经网络训练 | 权重参数优化 | 梯度信息不足 |
| 多目标优化 | 帕累托前沿搜索 | 多个冲突目标 |
| 工程优化 | 结构设计优化 | 复杂约束 |

### 可视化图表类型

- **粒子轨迹图**：粒子在解空间的运动轨迹
- **收敛曲线**：全局最优适应度变化
- **速度分布图**：粒子速度的统计分布
- **拓扑结构图**：粒子邻域关系

### 关键文献

| 论文名称 | 作者 | 年份 | 来源 |
|---------|------|------|------|
| Particle Swarm Optimization | Kennedy & Eberhart | 1995 | IEEE ICNN |
| A modified particle swarm optimizer | Shi & Eberhart | 1998 | IEEE ICEC |

### 代码实现要点

```python
# 常用库：pyswarms, scipy.optimize
import pyswarms as ps

# 定义优化目标函数
def objective_function(x):
    return np.sum(x**2, axis=1)

# 创建PSO优化器
options = {'c1': 0.5, 'c2': 0.3, 'w': 0.9}
optimizer = ps.single.GlobalBestPSO(n_particles=50, dimensions=2, options=options)

# 执行优化
best_cost, best_pos = optimizer.optimize(objective_function, iters=100)
```

---

## 6. 模拟退火算法 (Simulated Annealing, SA)

### 算法介绍

模拟退火算法模拟固体退火过程，通过概率性接受劣解来避免陷入局部最优。算法从高温开始，随着温度下降，接受劣解的概率逐渐降低。

**Metropolis准则**：
$$
P(accept) = \begin{cases}
1, & \Delta E < 0 \\
\exp(-\Delta E / T), & \Delta E \geq 0
\end{cases}
$$

**降温策略**：
- 线性降温：$T_{k+1} = \alpha \cdot T_k$
- 指数降温：$T_{k+1} = T_0 / (1 + \ln(k))$

### 适用范围

| 题型类型 | 典型问题 | 特征 |
|---------|---------|------|
| 组合优化 | 旅行商问题 | 离散解空间 |
| 调度问题 | 生产调度 | 复杂约束 |
| 图着色 | 地图着色、频率分配 | 约束满足 |
| VLSI设计 | 电路布局 | 大规模优化 |

### 可视化图表类型

- **温度曲线**：温度随迭代次数变化
- **能量曲线**：目标函数值变化
- **接受率图**：新解接受概率变化
- **解空间探索图**：解的搜索轨迹

### 关键文献

| 论文名称 | 作者 | 年份 | 来源 |
|---------|------|------|------|
| Optimization by Simulated Annealing | Kirkpatrick et al. | 1983 | Science |
| Very Large-Scale Integration | Metropolis et al. | 1953 | J. Chem. Phys. |

### 代码实现要点

```python
# 常用库：simanneal, scipy.optimize
from simanneal import Annealer

class TSPProblem(Annealer):
    def __init__(self, state, distance_matrix):
        self.state = state
        self.distance_matrix = distance_matrix

    def move(self):
        # 交换两个城市的位置
        a, b = random.sample(range(len(self.state)), 2)
        self.state[a], self.state[b] = self.state[b], self.state[a]

    def energy(self):
        # 计算总距离
        return sum(self.distance_matrix[self.state[i], self.state[i+1]]
                   for i in range(len(self.state)-1))
```

---

## 7. 蚁群算法 (Ant Colony Optimization, ACO)

### 算法介绍

蚁群算法模拟蚂蚁觅食过程中的信息素沟通机制。蚂蚁在路径上释放信息素，后续蚂蚁根据信息素浓度选择路径，正反馈机制使算法收敛到最优路径。

**状态转移概率**：
$$
P_{ij}^k = \begin{cases}
\frac{[\tau_{ij}]^\alpha [\eta_{ij}]^\beta}{\sum_{s \in allowed_k} [\tau_{is}]^\alpha [\eta_{is}]^\beta}, & j \in allowed_k \\
0, & \text{otherwise}
\end{cases}
$$

**信息素更新**：
$$
\tau_{ij} = (1 - \rho) \cdot \tau_{ij} + \sum_{k=1}^m \Delta \tau_{ij}^k
$$

### 适用范围

| 题型类型 | 典型问题 | 特征 |
|---------|---------|------|
| 路径规划 | 旅行商问题、车辆路径 | 图结构 |
| 调度问题 | 作业调度、项目调度 | 组合优化 |
| 网络路由 | 通信网络路由 | 动态环境 |
| 资源分配 | 任务分配、负载均衡 | 分配问题 |

### 可视化图表类型

- **路径图**：蚂蚁移动路径可视化
- **信息素热力图**：信息素浓度分布
- **收敛曲线**：最优解质量变化
- **蚂蚁分布图**：蚂蚁在解空间的分布

### 关键文献

| 论文名称 | 作者 | 年份 | 来源 |
|---------|------|------|------|
| Ant system: optimization by a colony | Dorigo & Gambardella | 1997 | IEEE Transactions on Systems, Man, and Cybernetics |
| The Ant System | Dorigo, Maniezzo & Colorni | 1991 | European Conference on Artificial Life |

### 代码实现要点

```python
# 常用库：aco, networkx
import numpy as np

def ant_colony_optimization(distance_matrix, n_ants=20, n_iterations=100,
                           alpha=1, beta=2, evaporation_rate=0.1):
    n_cities = len(distance_matrix)
    pheromone = np.ones((n_cities, n_cities)) / n_cities

    for iteration in range(n_iterations):
        # 所有蚂蚁构建路径
        paths = []
        for ant in range(n_ants):
            path = construct_path(pheromone, distance_matrix, alpha, beta)
            paths.append(path)

        # 更新信息素
        pheromone *= (1 - evaporation_rate)
        for path in paths:
            for i in range(len(path) - 1):
                pheromone[path[i], path[i+1]] += 1 / path_length(path, distance_matrix)
```

---

## 8. 差分进化算法 (Differential Evolution, DE)

### 算法介绍

差分进化算法是一种基于群体差异的进化算法，通过差分变异操作产生新个体。算法简单高效，特别适合连续优化问题。

**基本操作**：
1. **变异**：$V_i = X_{r1} + F \cdot (X_{r2} - X_{r3})$
2. **交叉**：$U_{ij} = \begin{cases} V_{ij}, & \text{rand} \leq CR \text{ or } j = j_{rand} \\ X_{ij}, & \text{otherwise} \end{cases}$
3. **选择**：贪心选择更优个体

**参数**：
- $F$：缩放因子（0.4-1.0）
- $CR$：交叉概率（0.1-0.9）

### 适用范围

| 题型类型 | 典型问题 | 特征 |
|---------|---------|------|
| 连续优化 | 函数优化 | 连续变量 |
| 参数估计 | 模型参数拟合 | 非线性优化 |
| 信号处理 | 滤波器设计 | 多维优化 |
| 控制系统 | PID参数整定 | 实时优化 |

### 可视化图表类型

- **进化曲线**：适应度随代数变化
- **种群分布图**：个体在解空间的分布
- **差异向量图**：变异操作示意图
- **参数敏感性图**：参数F和CR的影响

### 关键文献

| 论文名称 | 作者 | 年份 | 来源 |
|---------|------|------|------|
| Differential Evolution - A Simple and Efficient Heuristic for Global Optimization | Storn & Price | 1997 | Journal of Global Optimization |
| Differential Evolution: A Practical Approach to Global Optimization | Price, Storn & Lampinen | 2005 | Springer |

### 代码实现要点

```python
# 常用库：scipy.optimize.differential_evolution, DEAP
from scipy.optimize import differential_evolution

def objective_function(x):
    return sum(x**2)

bounds = [(-10, 10), (-10, 10), (-10, 10)]
result = differential_evolution(objective_function, bounds,
                                 strategy='best1bin',
                                 maxiter=1000,
                                 popsize=15,
                                 tol=1e-6)
```

---

## 9. 禁忌搜索算法 (Tabu Search, TS)

### 算法介绍

禁忌搜索算法通过记忆机制避免循环搜索，使用禁忌表记录最近访问的解，在指定迭代次数内不允许重复访问。

**核心要素**：
- **禁忌表**：存储禁忌对象
- **禁忌长度**：对象被禁忌的迭代次数
- **特赦规则**：某些情况下可解除禁忌
- **候选集**：邻域中的候选解

### 适用范围

| 题型类型 | 典型问题 | 特征 |
|---------|---------|------|
| 调度问题 | 作业调度、排班 | 组合优化 |
| 路径问题 | 旅行商问题、车辆路径 | 图搜索 |
| 设施选址 | 仓库选址、服务点布局 | 离散优化 |
| 图着色 | 地图着色、时间表问题 | 约束满足 |

### 可视化图表类型

- **搜索轨迹图**：解在搜索过程中的变化
- **禁忌表状态**：禁忌对象的变化
- **邻域结构图**：当前解的邻域
- **最优解更新图**：全局最优的更新过程

### 关键文献

| 论文名称 | 作者 | 年份 | 来源 |
|---------|------|------|------|
| Tabu Search - Part I | Fred Glover | 1989 | ORSA Journal on Computing |
| Tabu Search - Part II | Fred Glover | 1990 | ORSA Journal on Computing |

### 代码实现要点

```python
def tabu_search(initial_solution, objective_func, neighborhood_func,
                tabu_tenure=10, max_iterations=1000):
    current_solution = initial_solution
    best_solution = initial_solution
    tabu_list = []

    for iteration in range(max_iterations):
        # 生成候选解
        candidates = neighborhood_func(current_solution)

        # 过滤禁忌解
        non_tabu_candidates = [c for c in candidates if c not in tabu_list]

        # 选择最优候选解
        best_candidate = max(non_tabu_candidates, key=objective_func)

        # 更新当前解和禁忌表
        current_solution = best_candidate
        tabu_list.append(best_candidate)
        if len(tabu_list) > tabu_tenure:
            tabu_list.pop(0)

        if objective_func(best_candidate) > objective_func(best_solution):
            best_solution = best_candidate

    return best_solution
```

---

## 10. 灰狼优化算法 (Grey Wolf Optimizer, GWO)

### 算法介绍

灰狼优化算法模拟灰狼的社会等级和狩猎行为。算法将种群分为四个等级：α、β、δ和ω，通过前三个等级的个体引导种群向猎物（最优解）移动。

**位置更新公式**：
$$
\vec{X}(t+1) = \frac{\vec{X}_1 + \vec{X}_2 + \vec{X}_3}{3}
$$

其中：
$$
\vec{X}_1 = \vec{X}_\alpha - \vec{A}_1 \cdot |\vec{C}_1 \cdot \vec{X}_\alpha - \vec{X}|
$$
$$
\vec{X}_2 = \vec{X}_\beta - \vec{A}_2 \cdot |\vec{C}_2 \cdot \vec{X}_\beta - \vec{X}|
$$
$$
\vec{X}_3 = \vec{X}_\delta - \vec{A}_3 \cdot |\vec{C}_3 \cdot \vec{X}_\delta - \vec{X}|
$$

### 适用范围

| 题型类型 | 典型问题 | 特征 |
|---------|---------|------|
| 函数优化 | 多模态函数优化 | 非凸、非线性 |
| 参数优化 | 神经网络参数 | 高维搜索 |
| 工程优化 | 结构设计优化 | 复杂约束 |
| 能源系统 | 发电调度 | 非线性系统 |

### 可视化图表类型

- **等级位置图**：α、β、δ在解空间的位置
- **收敛曲线**：适应度随代数变化
- **三维轨迹图**： wolves在三维空间的移动轨迹
- **等级变化图**：个体等级的变化历史

### 关键文献

| 论文名称 | 作者 | 年份 | 来源 |
|---------|------|------|------|
| Grey Wolf Optimizer | Mirjalili, Mirjalili & Lewis | 2014 | Advances in Engineering Software |
| The Grey Wolf Optimizer | Sareh, Mirjalili & Lewis | 2014 | 2014 IEEE Congress on Evolutionary Computation |

### 代码实现要点

```python
import numpy as np

def grey_wolf_optimizer(objective_func, dim, bounds, n_wolves=30, max_iter=100):
    # 初始化灰狼位置
    wolves = np.random.uniform(bounds[0], bounds[1], (n_wolves, dim))

    # 初始化alpha, beta, delta
    alpha_pos = np.zeros(dim)
    beta_pos = np.zeros(dim)
    delta_pos = np.zeros(dim)

    for iteration in range(max_iter):
        # 更新每只狼的位置
        for i in range(n_wolves):
            # 计算与alpha, beta, delta的距离
            for j in range(3):
                # ... 位置更新逻辑
                pass

        # 更新alpha, beta, delta
        # ...

    return alpha_pos, alpha_score
```

---

## 11. 免疫算法 (Immune Algorithm, IA)

### 算法介绍

免疫算法模拟生物免疫系统的抗原识别、抗体产生、克隆选择、免疫记忆等机制。算法通过抗体与抗原的亲和度以及抗体之间的抑制关系维持种群多样性。

**核心操作**：
1. **抗原识别**：识别待优化问题
2. **抗体产生**：生成候选解
3. **亲和度计算**：评估解的质量
4. **克隆选择**：优质抗体克隆扩增
5. **亲和突变**：克隆抗体高频变异
6. **免疫抑制**：相似抗体相互抑制

### 适用范围

| 题型类型 | 典型问题 | 特征 |
|---------|---------|------|
| 函数优化 | 多峰函数优化 | 需要维持多样性 |
| 组合优化 | 旅行商问题 | NP-hard |
| 机器学习 | 特征选择 | 高维搜索 |
| 异常检测 | 网络入侵检测 | 模式识别 |

### 可视化图表类型

- **抗体分布图**：抗体在解空间的分布
- **亲和度热力图**：抗体与抗原的亲和度
- **克隆扩增图**：克隆过程可视化
- **多样性曲线**：种群多样性变化

### 关键文献

| 论文名称 | 作者 | 年份 | 来源 |
|---------|------|------|------|
| Artificial Immune Systems: A Novel Computational Intelligence Approach | de Castro & Timmis | 2002 | Springer |
| The Clonal Selection Algorithm with Engineering Applications | de Castro & Von Zuben | 2000 | GECCO |

### 代码实现要点

```python
import numpy as np

def immune_algorithm(objective_func, dim, bounds, n_antibodies=50,
                     clone_factor=5, mutation_rate=0.1, max_iter=100):
    # 初始化抗体种群
    antibodies = np.random.uniform(bounds[0], bounds[1], (n_antibodies, dim))

    for iteration in range(max_iter):
        # 计算亲和度
        affinity = np.array([objective_func(ab) for ab in antibodies])

        # 选择优质抗体
        selected_indices = np.argsort(affinity)[:n_antibodies//2]
        selected = antibodies[selected_indices]

        # 克隆扩增
        clones = []
        for ab in selected:
            for _ in range(clone_factor):
                clone = ab + np.random.normal(0, mutation_rate, dim)
                clones.append(clone)

        # 免疫抑制（去除相似抗体）
        # ...

        antibodies = np.array(clones)

    return best_antibody, best_affinity
```

---

## 12. 鲸鱼优化算法 (Whale Optimization Algorithm, WOA)

### 算法介绍

鲸鱼优化算法是Mirjalili等人于2016年提出的一种新型元启发式算法，模拟座头鲸的泡泡网捕食行为。算法通过座头鲸包围猎物、螺旋更新位置和随机搜索三种机制实现全局优化。

**位置更新公式**：

**包围猎物**：
$$
\vec{D} = |\vec{C} \cdot \vec{X}^*(t) - \vec{X}(t)|
$$
$$
\vec{X}(t+1) = \vec{X}^*(t) - \vec{A} \cdot \vec{D}
$$

**螺旋更新**：
$$
\vec{X}(t+1) = \vec{D}' \cdot e^{bl} \cdot \cos(2\pi l) + \vec{X}^*(t)
$$

其中 $\vec{D}' = |\vec{X}^*(t) - \vec{X}(t)|$ 表示鲸鱼与猎物的距离

**参数**：
- $\vec{A}$：收敛系数，随迭代从2线性递减到0
- $\vec{C}$：摇摆系数，[0, 2]随机数
- $b$：对数螺旋形状常数（通常取1）
- $l$：[-1, 1]随机数

### 适用范围

| 题型类型 | 典型问题 | 特征 |
|---------|---------|------|
| 连续优化 | 函数极值求解 | 连续变量、多维 |
| 工程优化 | 结构设计、参数优化 | 非线性约束 |
| 电力系统 | 经济调度、无功优化 | 复杂约束 |
| 机器学习 | 神经网络训练 | 参数优化 |

### 可视化图表类型

- **收敛曲线**：适应度随迭代次数变化
- **位置轨迹图**：鲸鱼在解空间的移动轨迹
- **螺旋包围图**：泡泡网捕食行为可视化
- **参数敏感性图**：参数b对算法性能的影响

### 关键文献

| 论文名称 | 作者 | 年份 | 来源 |
|---------|------|------|------|
| The Whale Optimization Algorithm | Mirjalili, Lewis | 2016 | Advances in Engineering Software |
| Whale Optimization Algorithm: A comprehensive review | Abdel-Basset et al. | 2023 | Expert Systems with Applications |

### 代码实现要点

```python
import numpy as np

def whale_optimization(objective_func, dim, bounds, n_whales=30, max_iter=100):
    # 初始化鲸鱼位置
    whales = np.random.uniform(bounds[0], bounds[1], (n_whales, dim))
    best_whale = whales[0].copy()
    best_fitness = objective_func(best_whale)

    for iteration in range(max_iter):
        # 线性递减a从2到0
        a = 2 - iteration * (2 / max_iter)

        for i in range(n_whales):
            r1 = np.random.rand()
            r2 = np.random.rand()

            A = 2 * a * r1 - a
            C = 2 * r2

            p = np.random.rand()

            if p < 0.5:
                # 包围机制
                if abs(A) < 1:
                    D = abs(C * best_whale - whales[i])
                    whales[i] = best_whale - A * D
                else:
                    # 随机搜索
                    random_whale = whales[np.random.randint(n_whales)]
                    D = abs(C * random_whale - whales[i])
                    whales[i] = random_whale - A * D
            else:
                # 螺旋更新
                D_prime = abs(best_whale - whales[i])
                b = 1
                l = (np.random.rand() * 2 - 1)
                whales[i] = D_prime * np.exp(b * l) * np.cos(2 * np.pi * l) + best_whale

            # 边界处理
            whales[i] = np.clip(whales[i], bounds[0], bounds[1])

            # 更新最优解
            fitness = objective_func(whales[i])
            if fitness < best_fitness:
                best_fitness = fitness
                best_whale = whales[i].copy()

    return best_whale, best_fitness
```

---

## 13. 麻雀搜索算法 (Sparrow Search Algorithm, SSA)

### 算法介绍

麻雀搜索算法是Xue等人于2020年提出的新型元启发式算法，模拟麻雀种群的觅食和反捕食行为。算法将麻雀分为发现者、跟随者和预警者三类，通过协同搜索实现快速收敛。

**发现者位置更新**：
$$
X_{i,j}^{t+1} = \begin{cases}
X_{i,j}^t \cdot \exp(-\frac{i}{\alpha \cdot iter_{max}}), & R_2 < ST \\
X_{i,j}^t + Q \cdot L, & R_2 \geq ST
\end{cases}
$$

**跟随者位置更新**：
$$
X_{i,j}^{t+1} = \begin{cases}
Q \cdot \exp(\frac{X_{worst} - X_{i,j}^t}{i^2}), & i > n/2 \\
X_{p}^{t+1} + |X_{i,j}^t - X_{p}^{t+1}| \cdot A^+ \cdot L, & \text{otherwise}
\end{cases}
$$

**预警者位置更新**：
$$
X_{i,j}^{t+1} = \begin{cases}
X_{best}^t + \beta \cdot |X_{i,j}^t - X_{best}^t|, & f_i > f_g \\
X_{i,j}^t + K \cdot \frac{|X_{i,j}^t - X_{worst}^t|}{f_i - f_w + \epsilon}, & f_i = f_g
\end{cases}
$$

**参数**：
- $ST$：安全阈值（0.2-0.8）
- $\alpha$：[0, 1]随机数
- $R_2$：预警值，[0, 1]随机数

### 适用范围

| 题型类型 | 典型问题 | 特征 |
|---------|---------|------|
| 函数优化 | 多模态函数优化 | 快速收敛 |
| 参数辨识 | 系统参数估计 | 高精度 |
| 调度优化 | 生产调度、资源分配 | 组合优化 |
| 工程设计 | 结构优化设计 | 实际约束 |

### 可视化图表类型

- **角色分布图**：发现者、跟随者、预警者的分布
- **收敛曲线**：适应度快速变化过程
- **位置更新图**：三类麻雀的位置更新轨迹
- **警戒值变化图**：安全阈值影响分析

### 关键文献

| 论文名称 | 作者 | 年份 | 来源 |
|---------|------|------|------|
| Sparrow search algorithm: A novel efficient algorithm | Xue & Shen | 2020 | Journal of Computational Design and Engineering |
| Improved sparrow search algorithm | Ouyang et al. | 2021 | Expert Systems with Applications |

### 代码实现要点

```python
import numpy as np

def sparrow_search_algorithm(objective_func, dim, bounds, n_sparrows=50,
                             max_iter=100, ST=0.8):
    # 初始化麻雀种群
    sparrows = np.random.uniform(bounds[0], bounds[1], (n_sparrows, dim))
    fitness = np.array([objective_func(s) for s in sparrows])

    # 排序并确定最佳和最差位置
    sorted_idx = np.argsort(fitness)
    best_pos = sparrows[sorted_idx[0]].copy()
    worst_pos = sparrows[sorted_idx[-1]].copy()
    best_fitness = fitness[sorted_idx[0]]
    worst_fitness = fitness[sorted_idx[-1]]

    # 发现者数量（前20%）
    n_discoverers = int(0.2 * n_sparrows)

    for iteration in range(max_iter):
        for i in range(n_sparrows):
            R2 = np.random.rand()
            if i < n_discoverers:
                # 发现者更新
                if R2 < ST:
                    sparrows[i] *= np.exp(-i / (np.random.rand() * max_iter))
                else:
                    sparrows[i] += np.random.randn()
            else:
                # 跟随者更新
                if i > n_sparrows / 2:
                    sparrows[i] = np.random.randn() * np.exp(
                        (worst_pos - sparrows[i]) / i**2)
                else:
                    A = np.floor(np.random.randn() * dim)
                    AA = A.T @ (A @ A.T)**-1 if A.shape else 0
                    sparrows[i] = best_pos + abs(sparrows[i] - best_pos) * AA

            # 边界处理
            sparrows[i] = np.clip(sparrows[i], bounds[0], bounds[1])

        # 预警者更新（适应度最差的10%）
        worst_indices = sorted_idx[-int(0.1 * n_sparrows):]
        for i in worst_indices:
            if fitness[i] > best_fitness:
                sparrows[i] = best_pos + np.random.randn() * abs(sparrows[i] - best_pos)
            else:
                sparrows[i] += np.random.randn() * abs(
                    sparrows[i] - worst_pos) / (fitness[i] - worst_fitness + 1e-10)

        # 更新适应度和最优解
        fitness = np.array([objective_func(s) for s in sparrows])
        current_best_idx = np.argmin(fitness)
        if fitness[current_best_idx] < best_fitness:
            best_fitness = fitness[current_best_idx]
            best_pos = sparrows[current_best_idx].copy()

    return best_pos, best_fitness
```

---

## 14. 多目标优化 (Multi-Objective Optimization, MOO)

### 算法介绍

多目标优化问题涉及多个相互冲突的目标函数，需要找到一组折衷解（Pareto最优解集）。

**标准形式**：
$$
\min F(x) = [f_1(x), f_2(x), \ldots, f_k(x)]^T
$$
$$
\text{s.t. } g_i(x) \leq 0, h_j(x) = 0, x \in \Omega
$$

**Pareto支配关系**：
- 解 $x_1$ 支配 $x_2$：$\forall i, f_i(x_1) \leq f_i(x_2)$ 且 $\exists i, f_i(x_1) < f_i(x_2)$
- Pareto最优解：不被任何其他解支配的解
- Pareto前沿：所有Pareto最优解在目标空间中的投影

### 常用算法

#### NSGA-II (Non-dominated Sorting Genetic Algorithm II)

**核心机制**：
1. **快速非支配排序**：将种群分为多个Pareto等级
2. **拥挤度距离**：保持解集分布均匀性
3. **精英策略**：保留优秀个体到下一代

**拥挤度计算**：
$$
D_{i,d} = \sum_{d=1}^{k} \frac{|f_d^{i+1} - f_d^{i-1}|}{f_d^{max} - f_d^{min}}
$$

#### MOEA/D (Multi-Objective Evolutionary Algorithm based on Decomposition)

**核心思想**：将多目标优化分解为多个单目标子问题

**分解方法**：
- 加权求和法：$\min \sum_{i=1}^k \lambda_i f_i(x)$
- Tchebycheff法：$\min \max_{i} \{\lambda_i |f_i(x) - z_i^*|\}$
- 边界交集法

### 适用范围

| 题型类型 | 典型问题 | 特征 |
|---------|---------|------|
| 工程设计 | 结构优化、参数设计 | 多冲突目标 |
| 资源分配 | 预算分配、投资组合 | 效益与成本权衡 |
| 调度问题 | 生产调度、任务分配 | 时间与成本 |
| 路径规划 | 物流路径、网络设计 | 距离与风险 |

### 可视化图表类型

- **Pareto前沿图**：多目标解的分布（二维/三维）
- **收敛曲线**：超体积指标随迭代变化
- **散点图**：解集在目标空间的分布
- **平行坐标图**：高维目标的可视化
- **热力图**：解集密度分布

### 关键文献

| 论文名称 | 作者 | 年份 | 来源 |
|---------|------|------|------|
| A fast and elitist multiobjective genetic algorithm: NSGA-II | Deb et al. | 2002 | IEEE TEVC |
| MOEA/D: A multiobjective evolutionary algorithm based on decomposition | Zhang & Li | 2007 | IEEE TEVC |
| Multi-Objective Optimization Using Evolutionary Algorithms | Deb | 2001 | Wiley |

### 代码实现要点

```python
# 常用库：pymoo, DEAP, platypus
from pymoo.algorithms.moo.nsga2 import NSGA2
from pymoo.optimize import minimize
from pymoo.problems import get_problem

# 定义问题
problem = get_problem("zdt1")

# 创建NSGA-II算法
algorithm = NSGA2(pop_size=100)

# 执行优化
result = minimize(problem,
                 algorithm,
                 ('n_gen', 200),
                 seed=1,
                 verbose=True)

# 获取Pareto前沿
pareto_front = result.F
pareto_set = result.X
```

---

## 15. 鲁棒优化 (Robust Optimization, RO)

### 算法介绍

鲁棒优化处理参数不确定性的优化问题，寻找在所有可能的不确定性实现下都能保持可行性和良好性能的解。

**不确定性集类型**：

1. **盒子不确定性集**：
$$
U = \{\xi : |\xi_j - \bar{\xi}_j| \leq \hat{\xi}_j, \forall j\}
$$

2. **椭球不确定性集**：
$$
U = \{\xi : (\xi - \bar{\xi})^T \Sigma^{-1} (\xi - \bar{\xi}) \leq \Gamma^2\}
$$

3. **多面体不确定性集**（Bertsimas-Sim模型）：
$$
U = \{\xi : \xi_j = \bar{\xi}_j + \eta_j \hat{\xi}_j, \|\eta\|_1 \leq \Gamma, \|\eta\|_\infty \leq 1\}
$$

**鲁棒对应问题**：
$$
\min_x \max_{\xi \in U} f(x, \xi)
$$
$$
\text{s.t. } g(x, \xi) \leq 0, \forall \xi \in U
$$

### 适用范围

| 题型类型 | 典型问题 | 特征 |
|---------|---------|------|
| 供应链优化 | 网络设计、库存管理 | 需求不确定性 |
| 金融投资 | 投资组合优化 | 收益率波动 |
| 能源系统 | 发电调度 | 可再生能源波动 |
| 工程设计 | 结构设计 | 参数偏差 |

### 可视化图表类型

- **不确定性集图**：参数不确定性的范围
- **鲁棒解与名义解对比**：解的性能对比
- **情景分析图**：不同情景下的解表现
- **敏感度分析图**：鲁棒性水平与目标关系

### 关键文献

| 论文名称 | 作者 | 年份 | 来源 |
|---------|------|------|------|
| Robust Optimization | Ben-Tal, El Ghaoui, Nemirovski | 2009 | Princeton University Press |
| The Price of Robustness | Bertsimas & Sim | 2004 | Operations Research |
| Robust optimization – a comprehensive review | Gabrel et al. | 2014 | European Journal of Operational Research |

### 代码实现要点

```python
import numpy as np
from scipy.optimize import minimize

def robust_optimization_nominal(objective_func, constraint_func,
                                nominal_params, uncertainty_budgets,
                                bounds, method='SLSQP'):
    """
    鲁棒优化：使用Bertsimas-Sim模型
    uncertainty_budgets: 每个参数的不确定性预算Gamma
    """
    def robust_objective(x):
        # 最坏情况目标（保守策略）
        worst_obj = objective_func(x, nominal_params)
        # 考虑参数扰动
        for i, (param, budget) in enumerate(zip(nominal_params, uncertainty_budgets)):
            perturbation = budget * np.sign(x[i]) if budget > 0 else 0
            worst_obj = max(worst_obj, objective_func(x, nominal_params + perturbation))
        return worst_obj

    def robust_constraint(x):
        # 鲁棒约束：满足所有不确定性实现
        return constraint_func(x, nominal_params)

    result = minimize(robust_objective,
                     x0=np.random.rand(len(nominal_params)),
                     bounds=bounds,
                     constraints={'type': 'ineq', 'fun': robust_constraint},
                     method=method)

    return result.x
```

---

## 优化算法选择指南

### 按问题规模选择

| 规模 | 推荐算法 | 说明 |
|------|---------|------|
| 小规模（<10变量） | 线性规划、分支定界 | 可求得精确解 |
| 中规模（10-100变量） | 整数规划、差分进化 | 平衡精度与效率 |
| 大规模（>100变量） | 启发式算法（GA、PSO、ACO） | 快速获得满意解 |

### 按问题类型选择

| 问题特征 | 推荐算法 |
|---------|---------|
| 线性目标+线性约束 | 线性规划 |
| 需要整数解 | 整数规划、分支定界 |
| 多阶段决策 | 动态规划 |
| 非凸、多峰 | 遗传算法、粒子群优化 |
| 图结构问题 | 蚁群算法、禁忌搜索 |
| 连续优化 | 差分进化、灰狼优化 |

### 按约束类型选择

| 约束类型 | 推荐算法 |
|---------|---------|
| 无约束 | 梯度下降、牛顿法、PSO、DE |
| 线性约束 | 线性规划、投影梯度法 |
| 非线性约束 | 序列二次规划、罚函数法 |
| 逻辑约束 | 整数规划、约束GA |
| 动态约束 | 动态规划、模型预测控制 |

---

## 参考文献

1. Dantzig, G. B. (1963). *Linear Programming and Extensions*. Princeton University Press.
2. Bellman, R. (1957). *Dynamic Programming*. Princeton University Press.
3. Holland, J. H. (1975). *Adaptation in Natural and Artificial Systems*. University of Michigan Press.
4. Kennedy, J., & Eberhart, R. (1995). Particle swarm optimization. *IEEE ICNN*, 1942-1948.
5. Kirkpatrick, S., Gelatt, C. D., & Vecchi, M. P. (1983). Optimization by simulated annealing. *Science*, 220(4598), 671-680.
6. Dorigo, M., & Gambardella, L. M. (1997). Ant colony system: a cooperative learning approach to the traveling salesman problem. *IEEE Transactions on Evolutionary Computation*, 1(1), 53-66.
7. Storn, R., & Price, K. (1997). Differential evolution – a simple and efficient heuristic for global optimization over continuous spaces. *Journal of Global Optimization*, 11(4), 341-359.
8. Glover, F. (1989). Tabu search – Part I. *ORSA Journal on Computing*, 1(3), 190-206.
9. Mirjalili, S., Mirjalili, S. M., & Lewis, A. (2014). Grey wolf optimizer. *Advances in Engineering Software*, 69, 46-61.
10. de Castro, L. N., & Timmis, J. (2002). *Artificial Immune Systems: A Novel Computational Intelligence Approach*. Springer.
